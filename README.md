#Create code for projects in future
This is the codespace for what i have in mind for my future research project


ğŸ“Œ How Code Works (Overview)
Your eye-tracking cursor with blink click system works in these steps:
Captures video from your webcam.
Detects your face and eyes using Dlib's face landmark predictor.
Finds your eye positions and calculates an average position.
Maps that position to a 3x3 grid (to determine cursor movement).
Moves the mouse cursor based on where you're looking.
Detects blinks using the Eye Aspect Ratio (EAR).
Plays a click sound and triggers a mouse click when a blink is detected.



1ï¸âƒ£ Project Title & Description
ğŸ“Œ Eye-Tracking Cursor with Blink Click
This project allows users to control their mouse cursor using eye movements and perform a click action by blinking. It uses OpenCV, Dlib, PyAutoGUI, and Pygame for implementation.

2ï¸âƒ£ Features
âœ… Moves the cursor based on eye position
âœ… Clicks when you blink
âœ… Plays a click sound when blinking
âœ… Uses a 3x3 grid system for smoother tracking

3ï¸âƒ£ Installation & Setup
ğŸ“Œ Requirements:
Make sure you have Python installed and install the necessary libraries using:

bash
Copy
Edit
pip install opencv-python dlib numpy pyautogui pygame
ğŸ“Œ Download the required files:

Place shape_predictor_68_face_landmarks.dat in the same folder as your script.

Place click_sound.mp3 in the same folder.

ğŸ“Œ Run the code:

bash
Copy
Edit
python eye_tracking_cursor.py
4ï¸âƒ£ How to Use
1ï¸âƒ£ Run the script and look at different areas of the screen.
2ï¸âƒ£ Your cursor will follow your eye movements.
3ï¸âƒ£ Blink to trigger a mouse click.
4ï¸âƒ£ Press Q to exit.

5ï¸âƒ£ Known Issues & Future Improvements
âš  May need calibration for different lighting conditions.
âš  Cursor movement can be refined for smoother control.
âœ¨ Future improvement: Implement a larger grid system for more precise tracking.

## Installation  
1. Clone this repository:  
git clone https://github.com/FariaSamanta/SHANA.git cd SHANA

markdown
Copy
Edit

2. Install dependencies:  
pip install -r requirements.txt

markdown
Copy
Edit

3. Extract the shape predictor model:  
python extract_bz2.py

shell
Copy
Edit

## Usage  
Run the main script:  
python eye_tracking_cursor.py

markdown
Copy
Edit

## Dependencies  
- `OpenCV`  
- `dlib`  
- `numpy`  
- `pygame` (for sound)  

## Files in This Repository
- `eye_tracking_cursor.py` â€“ Main program  
- `shape_predictor_68_face_landmarks.dat.bz2` â€“ Model for face tracking (must be extracted)  
- `click_sound.mp3` â€“ Click sound effect  
- `test_sound.py` â€“ For testing the sound  

## Contributors  
- **Faria Samanta Akbar** ğŸ‰  

## License  
This project is open-source. Feel free to modify and improve it!  

